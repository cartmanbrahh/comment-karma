{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting reddit comment karma | Web mining \n",
    "\n",
    "## Part II | Predicting using XGBoost  \n",
    "\n",
    "### Ankita BHATTACHARYA\n",
    "##### M2, Statistics & Econometrics, TSE\n",
    "\n",
    "This second notebook contains the sequel to the first part of the Ask Reddit database anaylsis. Part I saw the feature generation that will be used to predict the comment karma on our test set. \n",
    "\n",
    "Predictions will be carried out using XGBoost\n",
    "\n",
    "**Kernel : Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline \n",
    "- Loading required libraries\n",
    "- Importing the pickle files from Part I\n",
    "   - Importing the text mining features (obtained using LDA)\n",
    "   - Importing the network mining are other features \n",
    "- Quick look at our features \n",
    "- Further cleaning before prediction\n",
    "- Split : train, test and validation sets\n",
    "- Model : XGBoost implementation \n",
    "- Conclusion :  Feature importance\n",
    "- Exportation for kaggle prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univeral\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Normalization of variables\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# Prediction algorithm\n",
    "import xgboost as xgb\n",
    "\n",
    "# Hyper-parameter tuning\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from parfit import bestFit\n",
    "\n",
    "# Exportation\n",
    "import csv\n",
    "\n",
    "# Garbage collection\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the pickle files from the last notebook, Part I. Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dff.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the index of the test comment_ids - later to be used for the Kaggle Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = df[df['ups'].isnull()]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Importing the text mining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lda_features.pkl', 'rb') as f:\n",
    "    lda_features = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all features \n",
    "We need to merge the text mined and the network and time features. In order to do so, we first find the columns of lda_features that are not in the whole df and only concatenate with these colummns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = lda_features[lda_features.columns.difference(df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, inter], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick look : Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  features : ['num_words', 'words_caps', 'num_exclamation_marks', 'num_question_marks', 'num_punctuation', 'num_subject', 'urlcount', 'sub_reddits', 'time_between_comments', 'time_diff_parent', 'rep_first', 'thread_pop', 'comment_depth', 'count_nb', 'degree_centrality', 'betweenness_centrality', 'eigenvector_centrality', 'parent_score', 'nb_com_author', 'lexicalDiversity', 'is_referencing', 'hour_of_comment', 'day_of_comment', 'delet', 'dont', 'fuck', 'good', 'know', 'like', 'look', 'make', 'need', 'peopl', 'pleas', 'post', 'question', 'realli', 'thing', 'think', 'time', 'want', 'work', 'year']\n",
      "Total number of features :  43\n"
     ]
    }
   ],
   "source": [
    "numerical_features = ['num_words', 'words_caps', 'num_exclamation_marks', 'num_question_marks', \n",
    "                      'num_punctuation', 'num_subject', 'urlcount', 'sub_reddits',\n",
    "                      'time_between_comments', 'time_diff_parent', 'rep_first',\n",
    "                      'thread_pop','comment_depth','count_nb',\n",
    "                      'degree_centrality', 'betweenness_centrality', \n",
    "                      'eigenvector_centrality', \n",
    "                      'parent_score', 'nb_com_author','lexicalDiversity', 'is_referencing']\n",
    "\n",
    "other_time_related = ['hour_of_comment', 'day_of_comment']\n",
    "lda_features_names = list(inter)\n",
    "total_features = []\n",
    "total_features.extend(numerical_features)\n",
    "total_features.extend(other_time_related)\n",
    "total_features.extend(lda_features_names)\n",
    "\n",
    "\n",
    "print(\"Total  features :\", total_features)\n",
    "print(\"Total number of features : \", len(total_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further cleaning before the prediction\n",
    "\n",
    "Let us look at how our features are distributed. We see that variables like num_words or num_punctuations, or number of punctuations are heavily skewed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>words_caps</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>num_punctuation</th>\n",
       "      <th>num_subject</th>\n",
       "      <th>urlcount</th>\n",
       "      <th>sub_reddits</th>\n",
       "      <th>time_between_comments</th>\n",
       "      <th>time_diff_parent</th>\n",
       "      <th>...</th>\n",
       "      <th>thread_pop</th>\n",
       "      <th>comment_depth</th>\n",
       "      <th>count_nb</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>betweenness_centrality</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>nb_com_author</th>\n",
       "      <th>lexicalDiversity</th>\n",
       "      <th>is_referencing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.2349e+06</td>\n",
       "      <td>4.2349e+06</td>\n",
       "      <td>4.2349e+06</td>\n",
       "      <td>4.2349e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>2.51019e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "      <td>4.23496e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>25.7532</td>\n",
       "      <td>4.41557</td>\n",
       "      <td>0.12605</td>\n",
       "      <td>0.192282</td>\n",
       "      <td>143.334</td>\n",
       "      <td>1.14351</td>\n",
       "      <td>0.0428056</td>\n",
       "      <td>0.0477204</td>\n",
       "      <td>27906.6</td>\n",
       "      <td>16701</td>\n",
       "      <td>...</td>\n",
       "      <td>4909.74</td>\n",
       "      <td>2.88944</td>\n",
       "      <td>1.59273</td>\n",
       "      <td>0.0146589</td>\n",
       "      <td>0.0363002</td>\n",
       "      <td>0.0737727</td>\n",
       "      <td>216.64</td>\n",
       "      <td>23442.2</td>\n",
       "      <td>0.396484</td>\n",
       "      <td>0.0167359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47.0631</td>\n",
       "      <td>17.5429</td>\n",
       "      <td>0.68321</td>\n",
       "      <td>0.800421</td>\n",
       "      <td>264.107</td>\n",
       "      <td>2.54478</td>\n",
       "      <td>0.310381</td>\n",
       "      <td>0.475616</td>\n",
       "      <td>67661.5</td>\n",
       "      <td>42920</td>\n",
       "      <td>...</td>\n",
       "      <td>7260.5</td>\n",
       "      <td>7.74423</td>\n",
       "      <td>3.07449</td>\n",
       "      <td>0.0511761</td>\n",
       "      <td>0.128261</td>\n",
       "      <td>0.260848</td>\n",
       "      <td>733.785</td>\n",
       "      <td>81453.5</td>\n",
       "      <td>0.252035</td>\n",
       "      <td>0.12828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2333</td>\n",
       "      <td>1077</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.45641e-05</td>\n",
       "      <td>1.98022e-07</td>\n",
       "      <td>6.47385e-08</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.184466</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18760</td>\n",
       "      <td>7388</td>\n",
       "      <td>...</td>\n",
       "      <td>1487</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.79659e-05</td>\n",
       "      <td>8.57177e-06</td>\n",
       "      <td>4.54704e-05</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37462</td>\n",
       "      <td>22224</td>\n",
       "      <td>...</td>\n",
       "      <td>6845</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000300992</td>\n",
       "      <td>6.53684e-05</td>\n",
       "      <td>0.000185995</td>\n",
       "      <td>10</td>\n",
       "      <td>149</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3656</td>\n",
       "      <td>10000</td>\n",
       "      <td>328</td>\n",
       "      <td>680</td>\n",
       "      <td>10000</td>\n",
       "      <td>1215</td>\n",
       "      <td>99</td>\n",
       "      <td>65</td>\n",
       "      <td>2.67749e+06</td>\n",
       "      <td>2.55609e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>35812</td>\n",
       "      <td>416</td>\n",
       "      <td>885</td>\n",
       "      <td>0.196113</td>\n",
       "      <td>0.491092</td>\n",
       "      <td>0.998706</td>\n",
       "      <td>6761</td>\n",
       "      <td>312007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_words   words_caps num_exclamation_marks num_question_marks  \\\n",
       "count  4.23496e+06  4.23496e+06            4.2349e+06         4.2349e+06   \n",
       "mean       25.7532      4.41557               0.12605           0.192282   \n",
       "std        47.0631      17.5429               0.68321           0.800421   \n",
       "min              0            0                     0                  0   \n",
       "25%              4            1                     0                  0   \n",
       "50%             12            2                     0                  0   \n",
       "75%             28            4                     0                  0   \n",
       "max           3656        10000                   328                680   \n",
       "\n",
       "      num_punctuation num_subject     urlcount  sub_reddits  \\\n",
       "count      4.2349e+06  4.2349e+06  4.23496e+06  4.23496e+06   \n",
       "mean          143.334     1.14351    0.0428056    0.0477204   \n",
       "std           264.107     2.54478     0.310381     0.475616   \n",
       "min                 1           0            0            0   \n",
       "25%                25           0            0            0   \n",
       "50%                65           0            0            0   \n",
       "75%               154           1            0            0   \n",
       "max             10000        1215           99           65   \n",
       "\n",
       "      time_between_comments time_diff_parent  ...   thread_pop comment_depth  \\\n",
       "count           4.23496e+06      2.51019e+06  ...  4.23496e+06   4.23496e+06   \n",
       "mean                27906.6            16701  ...      4909.74       2.88944   \n",
       "std                 67661.5            42920  ...       7260.5       7.74423   \n",
       "min                       0                0  ...            1             1   \n",
       "25%                    2333             1077  ...           39             1   \n",
       "50%                   18760             7388  ...         1487             2   \n",
       "75%                   37462            22224  ...         6845             3   \n",
       "max             2.67749e+06      2.55609e+06  ...        35812           416   \n",
       "\n",
       "          count_nb degree_centrality betweenness_centrality  \\\n",
       "count  4.23496e+06       4.23496e+06            4.23496e+06   \n",
       "mean       1.59273         0.0146589              0.0363002   \n",
       "std        3.07449         0.0511761               0.128261   \n",
       "min              1                 0                      0   \n",
       "25%              1       1.45641e-05            1.98022e-07   \n",
       "50%              1       6.79659e-05            8.57177e-06   \n",
       "75%              2       0.000300992            6.53684e-05   \n",
       "max            885          0.196113               0.491092   \n",
       "\n",
       "      eigenvector_centrality parent_score nb_com_author lexicalDiversity  \\\n",
       "count            4.23496e+06  4.23496e+06   4.23496e+06      4.23496e+06   \n",
       "mean               0.0737727       216.64       23442.2         0.396484   \n",
       "std                 0.260848      733.785       81453.5         0.252035   \n",
       "min                        0         -333             1                0   \n",
       "25%              6.47385e-08           10             8         0.184466   \n",
       "50%              4.54704e-05           10            33         0.347826   \n",
       "75%              0.000185995           10           149         0.596774   \n",
       "max                 0.998706         6761        312007                1   \n",
       "\n",
       "      is_referencing  \n",
       "count    4.23496e+06  \n",
       "mean       0.0167359  \n",
       "std          0.12828  \n",
       "min                0  \n",
       "25%                0  \n",
       "50%                0  \n",
       "75%                0  \n",
       "max                1  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical_features].describe().apply(lambda i: i.apply(lambda x: format(x, 'g')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us normlize the variables before we proceed in order not to skew the predictions After a brief visual inspection we take features having s.d. > 4 to be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['num_words',\n",
       " 'words_caps',\n",
       " 'num_punctuation',\n",
       " 'time_between_comments',\n",
       " 'time_diff_parent',\n",
       " 'thread_pop',\n",
       " 'comment_depth',\n",
       " 'parent_score',\n",
       " 'nb_com_author']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting variables to normalize : 9\n",
    "to_normalize = [i for i in numerical_features if df[i].std() > 4]\n",
    "to_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns not useful for prediction\n",
    "# These columns are strings and will not be able to help in prediction\n",
    "to_drop = [\"created_utc\", \"subreddit_id\",\"subreddit\",\"id\", \"link_id\", \"name\", \"author\", \"body\", \"parent_id\"]\n",
    "df.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We divide the df into variables to normalize and those not to. \n",
    "# Creating the database containing vars to be normalized\n",
    "df_to_normalize = df[to_normalize]\n",
    "\n",
    "# Storing variables not to normalize apart\n",
    "rest_features = [f for f in total_features if f not in to_normalize]\n",
    "rest_features.append('ups')\n",
    "not_to_normalize = df[rest_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard normalization - subtract from mean and divide by standard deviation \n",
    "normalizer = StandardScaler()\n",
    "normed_np_array = normalizer.fit_transform(df_to_normalize.values)\n",
    "df_normalized = pd.DataFrame(normed_np_array, index=df_to_normalize.index, columns=df_to_normalize.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all the normalized and other features into one single dataframe\n",
    "df_normalized = pd.concat([df_normalized, not_to_normalize], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove datasets we will not use further from memory memory\n",
    "del lda_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>words_caps</th>\n",
       "      <th>num_punctuation</th>\n",
       "      <th>time_between_comments</th>\n",
       "      <th>time_diff_parent</th>\n",
       "      <th>thread_pop</th>\n",
       "      <th>comment_depth</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>nb_com_author</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>...</th>\n",
       "      <th>post</th>\n",
       "      <th>question</th>\n",
       "      <th>realli</th>\n",
       "      <th>thing</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>want</th>\n",
       "      <th>work</th>\n",
       "      <th>year</th>\n",
       "      <th>ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3218500</th>\n",
       "      <td>0.982655</td>\n",
       "      <td>1.230381</td>\n",
       "      <td>2.569661</td>\n",
       "      <td>-0.411513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.675951</td>\n",
       "      <td>-0.243981</td>\n",
       "      <td>-0.281609</td>\n",
       "      <td>-0.284693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218501</th>\n",
       "      <td>-0.525959</td>\n",
       "      <td>-0.194698</td>\n",
       "      <td>-0.523782</td>\n",
       "      <td>-0.389403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.675538</td>\n",
       "      <td>-0.243981</td>\n",
       "      <td>-0.281609</td>\n",
       "      <td>-0.285896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218502</th>\n",
       "      <td>-0.334726</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>-0.364755</td>\n",
       "      <td>-0.315447</td>\n",
       "      <td>-0.267777</td>\n",
       "      <td>-0.663142</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>-0.259804</td>\n",
       "      <td>-0.286817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218503</th>\n",
       "      <td>-0.122245</td>\n",
       "      <td>-0.080692</td>\n",
       "      <td>-0.092139</td>\n",
       "      <td>-0.406340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.675538</td>\n",
       "      <td>-0.243981</td>\n",
       "      <td>-0.281609</td>\n",
       "      <td>-0.287553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218504</th>\n",
       "      <td>-0.355974</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>-0.349610</td>\n",
       "      <td>0.167782</td>\n",
       "      <td>0.488607</td>\n",
       "      <td>0.841575</td>\n",
       "      <td>-0.114853</td>\n",
       "      <td>5.654737</td>\n",
       "      <td>-0.287320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_words  words_caps  num_punctuation  time_between_comments  \\\n",
       "3218500   0.982655    1.230381         2.569661              -0.411513   \n",
       "3218501  -0.525959   -0.194698        -0.523782              -0.389403   \n",
       "3218502  -0.334726   -0.137695        -0.364755              -0.315447   \n",
       "3218503  -0.122245   -0.080692        -0.092139              -0.406340   \n",
       "3218504  -0.355974   -0.137695        -0.349610               0.167782   \n",
       "\n",
       "         time_diff_parent  thread_pop  comment_depth  parent_score  \\\n",
       "3218500               NaN   -0.675951      -0.243981     -0.281609   \n",
       "3218501               NaN   -0.675538      -0.243981     -0.281609   \n",
       "3218502         -0.267777   -0.663142       0.014276     -0.259804   \n",
       "3218503               NaN   -0.675538      -0.243981     -0.281609   \n",
       "3218504          0.488607    0.841575      -0.114853      5.654737   \n",
       "\n",
       "         nb_com_author  num_exclamation_marks  ...  post  question  realli  \\\n",
       "3218500      -0.284693                    0.0  ...   NaN       NaN     NaN   \n",
       "3218501      -0.285896                    0.0  ...   NaN       NaN     NaN   \n",
       "3218502      -0.286817                    0.0  ...   NaN       NaN     NaN   \n",
       "3218503      -0.287553                    0.0  ...   NaN       NaN     NaN   \n",
       "3218504      -0.287320                    0.0  ...   NaN       NaN     NaN   \n",
       "\n",
       "         thing  think  time  want  work  year  ups  \n",
       "3218500    NaN    NaN   NaN   NaN   NaN   NaN  NaN  \n",
       "3218501    NaN    NaN   NaN   NaN   NaN   NaN  NaN  \n",
       "3218502    NaN    NaN   NaN   NaN   NaN   NaN  NaN  \n",
       "3218503    NaN    NaN   NaN   NaN   NaN   NaN  NaN  \n",
       "3218504    NaN    NaN   NaN   NaN   NaN   NaN  NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = df_normalized[df_normalized['ups'].isnull()]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>words_caps</th>\n",
       "      <th>num_punctuation</th>\n",
       "      <th>time_between_comments</th>\n",
       "      <th>time_diff_parent</th>\n",
       "      <th>thread_pop</th>\n",
       "      <th>comment_depth</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>nb_com_author</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>...</th>\n",
       "      <th>post</th>\n",
       "      <th>question</th>\n",
       "      <th>realli</th>\n",
       "      <th>thing</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>want</th>\n",
       "      <th>work</th>\n",
       "      <th>year</th>\n",
       "      <th>ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.100997</td>\n",
       "      <td>0.033314</td>\n",
       "      <td>-0.092139</td>\n",
       "      <td>-0.412444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.292506</td>\n",
       "      <td>-0.243981</td>\n",
       "      <td>-0.281609</td>\n",
       "      <td>-0.287136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2.684066</td>\n",
       "      <td>0.065346</td>\n",
       "      <td>0.294007</td>\n",
       "      <td>13.695853</td>\n",
       "      <td>0.079638</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.334726</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>-0.360969</td>\n",
       "      <td>-0.412444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.024621</td>\n",
       "      <td>-0.243981</td>\n",
       "      <td>-0.281609</td>\n",
       "      <td>-0.287737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.110765</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.099479</td>\n",
       "      <td>0.070763</td>\n",
       "      <td>215594.422390</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.525959</td>\n",
       "      <td>-0.023689</td>\n",
       "      <td>-0.527568</td>\n",
       "      <td>-0.412444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.321914</td>\n",
       "      <td>-0.243981</td>\n",
       "      <td>-0.281609</td>\n",
       "      <td>-0.287099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.249734</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>-0.338251</td>\n",
       "      <td>-0.412444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.474312</td>\n",
       "      <td>-0.243981</td>\n",
       "      <td>-0.281609</td>\n",
       "      <td>-0.287737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.051699</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>280496.272504</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.366461</td>\n",
       "      <td>-0.080692</td>\n",
       "      <td>0.369795</td>\n",
       "      <td>-0.412429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.292506</td>\n",
       "      <td>-0.243981</td>\n",
       "      <td>-0.281609</td>\n",
       "      <td>-0.287774</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_words  words_caps  num_punctuation  time_between_comments  \\\n",
       "0  -0.100997    0.033314        -0.092139              -0.412444   \n",
       "1  -0.334726   -0.137695        -0.360969              -0.412444   \n",
       "2  -0.525959   -0.023689        -0.527568              -0.412444   \n",
       "3  -0.249734   -0.137695        -0.338251              -0.412444   \n",
       "4   0.366461   -0.080692         0.369795              -0.412429   \n",
       "\n",
       "   time_diff_parent  thread_pop  comment_depth  parent_score  nb_com_author  \\\n",
       "0               NaN   -0.292506      -0.243981     -0.281609      -0.287136   \n",
       "1               NaN    1.024621      -0.243981     -0.281609      -0.287737   \n",
       "2               NaN    0.321914      -0.243981     -0.281609      -0.287099   \n",
       "3               NaN   -0.474312      -0.243981     -0.281609      -0.287737   \n",
       "4               NaN   -0.292506      -0.243981     -0.281609      -0.287774   \n",
       "\n",
       "   num_exclamation_marks  ...  post  question    realli     thing  \\\n",
       "0                    0.0  ...  0.05      0.05  2.684066  0.065346   \n",
       "1                    0.0  ...  0.05      0.05  0.110765  0.050000   \n",
       "2                    0.0  ...  0.05      0.05  0.050000  0.050000   \n",
       "3                    0.0  ...  0.05      0.05  0.051699  0.050000   \n",
       "4                    0.0  ...  0.05      0.05  0.050000  0.050000   \n",
       "\n",
       "           think       time           want  work  year    ups  \n",
       "0       0.294007  13.695853       0.079638  0.05  0.05    3.0  \n",
       "1       0.099479   0.070763  215594.422390  0.05  0.05    3.0  \n",
       "2       0.050000   0.050000       0.050000  0.05  0.05    5.0  \n",
       "3  280496.272504   0.050000       0.050000  0.05  0.05    1.0  \n",
       "4       0.050000   0.050000       0.050000  0.05  0.05  101.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df_normalized[df_normalized['ups'].notnull()]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove datasets we will not use further from memory memory\n",
    "\n",
    "del df_normalized\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now taking apart the **ups** variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_df.ups\n",
    "train_df= train_df.drop('ups', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop('ups', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the train set into into train (80%) and validation (20%) sets. This will be then used to check for overfitting in the section to follow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, y_train, y_validation = train_test_split(train_df, train_y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model : XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:53:40] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:53:43] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:53:47] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:53:51] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:53:55] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:53:58] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:02] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:05] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:08] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:11] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:14] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:17] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:20] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:23] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:27] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:29] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:33] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:36] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:39] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:42] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:45] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:48] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:51] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:54] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:54:58] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:01] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:04] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:07] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:10] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:13] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:16] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:19] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:22] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:25] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:28] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:32] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:36] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:39] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:43] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:46] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:49] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:53] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:55:56] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:00] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:03] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:06] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:09] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:12] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 86 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:56:15] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:19] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:22] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:25] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:28] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:31] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:34] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:37] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:40] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:43] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:46] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:49] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:52] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:54] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:56:57] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:00] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:03] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:06] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:09] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:12] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:15] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:18] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 60 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:21] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:24] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:27] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:30] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:33] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:36] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:39] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:42] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:45] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 66 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:47] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:50] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:54] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:57:57] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:00] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:03] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:06] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:09] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:12] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:15] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:18] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:21] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:24] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:27] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:30] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:33] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:35] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 60 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:58:38] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:42] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:45] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10:58:47] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 84 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, eta=0.1, gamma=0,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.100000001, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=-1, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=1139, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us first run a naive model without selecting any params like learning rate, n_estimators or the depth we will later run a grid sea\n",
    "xgb_reg = xgb.XGBRegressor(n_jobs=-1, random_state=1139, verbosity=2, colsample_bytree=1, eta = 0.1, max_depth = 6)\n",
    "xgb_reg.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for overfitting\n",
    "\n",
    "We check for overfitting using the mean absolute error compared to the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE: 8.4\n",
      "Validation MAE: 8.82\n"
     ]
    }
   ],
   "source": [
    "predicted_train = xgb_reg.predict(X_train.values)\n",
    "predicted_validation = xgb_reg.predict(X_validation.values)\n",
    "train_MAE = round(mean_absolute_error(y_train, predicted_train), 2)\n",
    "validation_MAE = round(mean_absolute_error(y_validation, predicted_validation), 2)\n",
    "print(\"Training MAE:\", train_MAE)\n",
    "print(\"Validation MAE:\", validation_MAE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training MAE is less than the validation MAE. So how to deal with overfitting ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": np.array([45, 60, 75]),\n",
    "    \"max_depth\": np.array([5,6,9])\n",
    "}\n",
    "\n",
    "xgb_1 = xgb.XGBRegressor(\n",
    "    eta = 0.1,\n",
    "    njobs = -1,\n",
    "    seed=1139)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first method I tried was using GridSearchCV (inspired by: https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost) but this would take too long and my computer would crash. After having searched on the internet for other ways to gridsearch I found the parfit library which has a bestFit function to tune the model by brute search. Here the metric chosen was the mean absolute error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = 3\n",
    "# param_comb = 5\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "# grid = GridSearchCV(estimator=xgb_1, param_grid=params, scoring='roc_auc',  cv=skf.split(X_train, y_train), verbose=3 )\n",
    "# grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------FITTING MODELS-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   9 | elapsed: 22.4min remaining: 78.4min\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   9 | elapsed: 24.9min remaining: 49.7min\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed: 26.1min remaining: 32.7min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   9 | elapsed: 26.6min remaining: 21.3min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed: 26.7min remaining: 13.3min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed: 27.5min remaining:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 32.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed: 32.1min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------SCORING MODELS-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:    4.9s remaining:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   10.6s finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model, best_score, all_models, all_scores = bestFit(\n",
    "    model = xgb_1,\n",
    "    paramGrid = ParameterGrid(params), \n",
    "    X_train = X_train,\n",
    "    y_train = y_train,\n",
    "    X_val = X_validation,\n",
    "    y_val = y_validation,\n",
    "    metric = mean_absolute_error,\n",
    "    scoreLabel = \"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, eta=0.1, gamma=0,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.100000001, max_delta_step=0, max_depth=9,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=45, n_jobs=8, njobs=-1, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=1139, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=1139, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the graphic above we tried using the best model of 45 estimators and 9 depth levels. The score was 9.59 on Kaggle, but the best performance on Kaggle - **9.38**, was rendered by another combination of the parameters : **60 estimators and a depth of 6  with a learning rate of 0.2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n_estimators = 60\n",
    "best_max_depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:49:54] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:49:57] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:00] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:03] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:06] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:08] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:12] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:15] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:18] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 114 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:22] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:25] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:29] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:32] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:35] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:39] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:42] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:45] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:48] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:51] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:54] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:50:57] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:00] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:04] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:07] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:10] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:13] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 112 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:16] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:19] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:21] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:24] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:27] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:30] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:33] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:36] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:38] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 126 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:41] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:44] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 62 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:47] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 48 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:50] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:53] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:56] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:51:58] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:02] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:05] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:08] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 124 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:11] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:14] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:17] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 52 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:52:20] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:22] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:25] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:27] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:30] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:33] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 66 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:36] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 120 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:39] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:42] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 122 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:45] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:48] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12:52:50] INFO: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/tree/updater_prune.cc:101: tree pruning end, 104 extra nodes, 0 pruned nodes, max_depth=6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.8, eta=0.2, gamma=0,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.200000003, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=60, n_jobs=-1, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=1139, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, seed=1139, subsample=0.9,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg_best = xgb.XGBRegressor(n_estimators=best_n_estimators,\n",
    "                                eta=0.2,\n",
    "                                max_depth=best_max_depth,\n",
    "                                subsample=0.9,\n",
    "                                colsample_bytree=0.8,\n",
    "                                gamma=0,\n",
    "                                n_jobs=-1,\n",
    "                                verbosity=2,\n",
    "                                seed=1139)\n",
    "\n",
    "xgb_reg_best.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Conclusion : Feature Importance\n",
    "We now want to see which feature contributed the most to the model. \n",
    "- We see that the neighbour count has the highest score followed by the variable capturing replies to the first comment \n",
    "- Structural and time based features are a lot more important than text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>degree_centrality</th>\n",
       "      <td>0.033247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_diff_parent</th>\n",
       "      <td>0.056725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parent_score</th>\n",
       "      <td>0.058122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rep_first</th>\n",
       "      <td>0.138812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_nb</th>\n",
       "      <td>0.423887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     weight\n",
       "degree_centrality  0.033247\n",
       "time_diff_parent   0.056725\n",
       "parent_score       0.058122\n",
       "rep_first          0.138812\n",
       "count_nb           0.423887"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_weights = pd.DataFrame(xgb_reg_best.feature_importances_, columns=['weight'], index=X_train.columns)\n",
    "feature_weights.sort_values('weight', inplace=True)\n",
    "feature_weights.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle prediction\n",
    "kaggle_prediction = np.round(xgb_reg_best.predict(test_df.values))\n",
    "predict = pd.DataFrame(kaggle_prediction, columns = [\"predicted\"], index = ind )\n",
    "predict.to_csv(\"prediction.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  You have reached the end of this notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
